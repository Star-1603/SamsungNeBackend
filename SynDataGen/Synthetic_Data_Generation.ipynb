{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYS7Ryo6GgIW",
        "outputId": "3741b21d-73ec-4fd2-9307-abff49f80d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctgan\n",
            "  Downloading ctgan-0.10.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm<5,>=4.29 in /usr/local/lib/python3.10/dist-packages (from ctgan) (4.67.1)\n",
            "Collecting rdt>=1.11.0 (from ctgan)\n",
            "  Downloading rdt-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan) (2.5.1+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.11.0->ctgan) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.11.0->ctgan) (1.6.0)\n",
            "Collecting Faker>=17 (from rdt>=1.11.0->ctgan)\n",
            "  Downloading Faker-33.3.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->ctgan) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.11.0->ctgan) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.11.0->ctgan) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan) (3.0.2)\n",
            "Downloading ctgan-0.10.2-py3-none-any.whl (23 kB)\n",
            "Downloading rdt-1.13.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Faker-33.3.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Faker, rdt, ctgan\n",
            "Successfully installed Faker-33.3.1 ctgan-0.10.2 rdt-1.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ctgan pandas numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv\n"
      ],
      "metadata": {
        "id": "biR3N5lJKBuI",
        "outputId": "07d4f74a-7bb6-4b38-bd30-bad6db715886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sdv\n",
            "  Downloading sdv-1.17.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting boto3<2.0.0,>=1.28 (from sdv)\n",
            "  Downloading boto3-1.35.97-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<2.0.0,>=1.31 (from sdv)\n",
            "  Downloading botocore-1.35.97-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (3.1.0)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.67.1)\n",
            "Collecting copulas>=0.12.0 (from sdv)\n",
            "  Downloading copulas-0.12.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: ctgan>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from sdv) (0.10.2)\n",
            "Collecting deepecho>=0.6.1 (from sdv)\n",
            "  Downloading deepecho-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: rdt>=1.13.2.dev0 in /usr/local/lib/python3.10/dist-packages (from sdv) (1.13.2)\n",
            "Collecting sdmetrics>=0.17.0 (from sdv)\n",
            "  Downloading sdmetrics-0.18.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.10/dist-packages (from sdv) (4.3.6)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sdv) (6.0.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.3.0)\n",
            "Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.10/dist-packages (from copulas>=0.12.0->sdv) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from copulas>=0.12.0->sdv) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from ctgan>=0.10.2->sdv) (2.5.1+cu121)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->sdv) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->sdv) (2024.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.13.2.dev0->sdv) (1.6.0)\n",
            "Requirement already satisfied: Faker>=17 in /usr/local/lib/python3.10/dist-packages (from rdt>=1.13.2.dev0->sdv) (33.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from Faker>=17->rdt>=1.13.2.dev0->sdv) (4.12.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.10.0->copulas>=0.12.0->sdv) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.10.0->copulas>=0.12.0->sdv) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.13.2.dev0->sdv) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->rdt>=1.13.2.dev0->sdv) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.2->sdv) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.2->sdv) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.2->sdv) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.2->sdv) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->ctgan>=0.10.2->sdv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->ctgan>=0.10.2->sdv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->ctgan>=0.10.2->sdv) (3.0.2)\n",
            "Downloading sdv-1.17.3-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.3/154.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.97-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.97-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading copulas-0.12.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepecho-0.6.1-py3-none-any.whl (27 kB)\n",
            "Downloading sdmetrics-0.18.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, deepecho, copulas, sdmetrics, boto3, sdv\n",
            "Successfully installed boto3-1.35.97 botocore-1.35.97 copulas-0.12.0 deepecho-0.6.1 jmespath-1.0.1 s3transfer-0.10.4 sdmetrics-0.18.0 sdv-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "McJNeVozKdSA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Read data from the CSV file\n",
        "csv_file_path = 'Hadoop_NE.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame from CSV file:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqtLbdzmJnah",
        "outputId": "d3f4b798-a76d-4086-dfd6-209c37fe32be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame from CSV file:\n",
            "   LineId        Date          Time Level Process  \\\n",
            "0       1  2015-10-18  18:01:47,978  INFO    main   \n",
            "1       2  2015-10-18  18:01:48,963  INFO    main   \n",
            "2       3  2015-10-18  18:01:48,963  INFO    main   \n",
            "3       4  2015-10-18  18:01:49,228  INFO    main   \n",
            "4       5  2015-10-18  18:01:50,353  INFO    main   \n",
            "\n",
            "                                        Component  \\\n",
            "0  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "1  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "2  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "3  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "4  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "\n",
            "                                             Content EventId  \\\n",
            "0  Created MRAppMaster for application appattempt...     E29   \n",
            "1                             Executing with tokens:     E42   \n",
            "2  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...     E61   \n",
            "3                      Using mapred newApiCommitter.    E111   \n",
            "4                 OutputCommitter set in config null     E76   \n",
            "\n",
            "                                       EventTemplate  \n",
            "0  Created MRAppMaster for application appattempt...  \n",
            "1                             Executing with tokens:  \n",
            "2  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...  \n",
            "3                      Using mapred newApiCommitter.  \n",
            "4                 OutputCommitter set in config null  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split IP Address into four numerical segments\n",
        "df[[\"IP_Segment_1\", \"IP_Segment_2\", \"IP_Segment_3\", \"IP_Segment_4\"]] = df[\"IP Address\"].str.split(\".\", expand=True)\n",
        "\n",
        "# Convert IP segments to integers\n",
        "for segment in [\"IP_Segment_1\", \"IP_Segment_2\", \"IP_Segment_3\", \"IP_Segment_4\"]:\n",
        "    df[segment] = df[segment].astype(int)\n",
        "\n",
        "# Drop the original IP Address column\n",
        "df = df.drop(columns=[\"IP Address\"])\n",
        "print(\"DataFrame after splitting IP Address:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y7o4sktPX0U",
        "outputId": "4a739d53-b296-49a7-816f-0186d5efb9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after splitting IP Address:\n",
            "   Device Name Device Type     Vendor Model Number Serial Number  \\\n",
            "0    Router-01      Router      Cisco       XR1000      12345ABC   \n",
            "1    Switch-01      Switch    Juniper       EX4200      67890DEF   \n",
            "2  Firewall-01    Firewall  Palo Alto       PA-850      11223GHI   \n",
            "\n",
            "  Operating System Version        MAC Address                Location  \\\n",
            "0                  v12.1.3  00:1B:44:11:3A:B7  Data Center A, Rack 12   \n",
            "1                  v14.2.1  00:1B:44:11:3A:B8   Data Center B, Rack 5   \n",
            "2                   v8.5.6  00:1B:44:11:3A:B9   Data Center C, Rack 8   \n",
            "\n",
            "   CPU Usage (%)  Storage Usage (GB)  Heat (C)  IP_Segment_1  IP_Segment_2  \\\n",
            "0             30                 120        55           192           168   \n",
            "1             40                 250        60           192           168   \n",
            "2             35                  80        45           192           168   \n",
            "\n",
            "   IP_Segment_3  IP_Segment_4  \n",
            "0             1             1  \n",
            "1             1             2  \n",
            "2             1             3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XyeSmO-SOf2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "\n",
        "# Read data from the CSV file\n",
        "csv_file_path = 'Hadoop_NE.csv'  # Replace with your actual CSV file path\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame from CSV file:\")\n",
        "print(df.head())\n",
        "\n",
        "# Define metadata explicitly for a single table\n",
        "metadata = SingleTableMetadata()\n",
        "\n",
        "# Add fields to metadata\n",
        "metadata.add_column(\"LineId\", sdtype=\"id\")\n",
        "metadata.add_column(\"Date\", sdtype=\"datetime\")\n",
        "metadata.add_column(\"Time\", sdtype=\"datetime\")\n",
        "metadata.add_column(\"Level\", sdtype=\"categorical\")\n",
        "metadata.add_column(\"Process\", sdtype=\"categorical\")\n",
        "metadata.add_column(\"Component\", sdtype=\"categorical\")\n",
        "metadata.add_column(\"Content\", sdtype=\"text\")\n",
        "metadata.add_column(\"EventId\", sdtype=\"categorical\")\n",
        "metadata.add_column(\"EventTemplate\", sdtype=\"categorical\")\n",
        "\n",
        "# Set the primary key\n",
        "#metadata.set_primary_key(\"Process\")\n",
        "\n",
        "# Print metadata to verify it matches your expectations\n",
        "print(\"Metadata defined successfully!\")\n",
        "print(metadata.to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04SeVX1pQT1Q",
        "outputId": "100f1ef9-c802-436d-98b3-3d3ff77f364f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame from CSV file:\n",
            "   LineId        Date          Time Level Process  \\\n",
            "0       1  2015-10-18  18:01:47,978  INFO    main   \n",
            "1       2  2015-10-18  18:01:48,963  INFO    main   \n",
            "2       3  2015-10-18  18:01:48,963  INFO    main   \n",
            "3       4  2015-10-18  18:01:49,228  INFO    main   \n",
            "4       5  2015-10-18  18:01:50,353  INFO    main   \n",
            "\n",
            "                                        Component  \\\n",
            "0  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "1  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "2  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "3  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "4  org.apache.hadoop.mapreduce.v2.app.MRAppMaster   \n",
            "\n",
            "                                             Content EventId  \\\n",
            "0  Created MRAppMaster for application appattempt...     E29   \n",
            "1                             Executing with tokens:     E42   \n",
            "2  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...     E61   \n",
            "3                      Using mapred newApiCommitter.    E111   \n",
            "4                 OutputCommitter set in config null     E76   \n",
            "\n",
            "                                       EventTemplate  \n",
            "0  Created MRAppMaster for application appattempt...  \n",
            "1                             Executing with tokens:  \n",
            "2  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (app...  \n",
            "3                      Using mapred newApiCommitter.  \n",
            "4                 OutputCommitter set in config null  \n",
            "Metadata defined successfully!\n",
            "{'columns': {'LineId': {'sdtype': 'id'}, 'Date': {'sdtype': 'datetime'}, 'Time': {'sdtype': 'datetime'}, 'Level': {'sdtype': 'categorical'}, 'Process': {'sdtype': 'categorical'}, 'Component': {'sdtype': 'categorical'}, 'Content': {'sdtype': 'text', 'pii': True}, 'EventId': {'sdtype': 'categorical'}, 'EventTemplate': {'sdtype': 'categorical'}}, 'METADATA_SPEC_VERSION': 'SINGLE_TABLE_V1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sdv.single_table import CTGANSynthesizer\n",
        "import pandas as pd\n",
        "\n",
        "# Validate the metadata\n",
        "metadata.validate()\n",
        "\n",
        "# Initialize and train CTGAN\n",
        "ctgan = CTGANSynthesizer(metadata)\n",
        "ctgan.fit(df)\n",
        "\n",
        "print(\"CTGAN model trained successfully!\")\n",
        "\n",
        "# Generate synthetic data\n",
        "synthetic_data = ctgan.sample(1000)\n",
        "\n",
        "# Ensure that Date and Time columns are in correct format for synthetic data\n",
        "synthetic_data[\"Date\"] = pd.to_datetime(synthetic_data[\"Date\"])\n",
        "\n",
        "# Function to format time to two decimal places for seconds\n",
        "def format_time(time):\n",
        "    # Extract only the time part from the datetime\n",
        "    time_in_seconds = time.second + time.microsecond / 1e6\n",
        "    # Format time to two decimal places\n",
        "    formatted_time = f\"{int(time.hour):02}:{int(time.minute):02}:{int(time_in_seconds):02}.{int((time_in_seconds - int(time_in_seconds)) * 100):02}\"\n",
        "    return formatted_time\n",
        "\n",
        "# Apply the formatting function to the 'Time' column\n",
        "synthetic_data[\"Time\"] = pd.to_datetime(synthetic_data[\"Time\"]).apply(format_time)\n",
        "\n",
        "# Ensure 'Content' corresponds to the proper 'Level'\n",
        "level_content_map = (\n",
        "    df.groupby(\"Level\")[\"Content\"]\n",
        "    .apply(lambda x: x.unique())\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "def match_content_with_level(row):\n",
        "    valid_content = level_content_map.get(row[\"Level\"], [])\n",
        "    valid_content = valid_content.tolist() if isinstance(valid_content, np.ndarray) else valid_content\n",
        "    if row[\"Content\"] not in valid_content:\n",
        "        # Pick a random valid content for the given level if the content is invalid\n",
        "        return valid_content[0] if valid_content else None  # Handle empty valid_content\n",
        "    return row[\"Content\"]\n",
        "\n",
        "synthetic_data[\"Content\"] = synthetic_data.apply(match_content_with_level, axis=1)\n",
        "\n",
        "# Save the synthetic data to a CSV file\n",
        "output_file = \"synthetic_network_events_v4.csv\"\n",
        "synthetic_data.to_csv(output_file, index=False)\n",
        "print(f\"Synthetic data saved to '{output_file}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC57_Dn7PfGM",
        "outputId": "0bf12b4f-81e5-4b62-e944-e6ea36e6e309"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sdv/single_table/base.py:119: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sdv/metadata/single_table.py:1217: UserWarning: No 'datetime_format' is present in the metadata for the following columns:\n",
            "Column Name   sdtype datetime_format\n",
            "       Date datetime            None\n",
            "       Time datetime            None\n",
            "Without this specification, SDV may not be able to accurately parse the data. We recommend adding datetime formats using 'update_column'.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/sdv/_utils.py:54: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  return _guess_datetime_format_for_array(value)\n",
            "/usr/local/lib/python3.10/dist-packages/rdt/transformers/datetime.py:138: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  self.datetime_format = _guess_datetime_format_for_array(datetime_array)\n",
            "/usr/local/lib/python3.10/dist-packages/rdt/transformers/datetime.py:98: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data = pd.to_datetime(data, format=pandas_datetime_format)\n",
            "/usr/local/lib/python3.10/dist-packages/rdt/transformers/datetime.py:98: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data = pd.to_datetime(data, format=pandas_datetime_format)\n",
            "/usr/local/lib/python3.10/dist-packages/rdt/transformers/datetime.py:98: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data = pd.to_datetime(data, format=pandas_datetime_format)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTGAN model trained successfully!\n",
            "Synthetic data saved to 'synthetic_network_events_v4.csv'\n"
          ]
        }
      ]
    }
  ]
}